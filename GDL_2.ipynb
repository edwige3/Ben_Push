{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWwwHcWOPqLe"
      },
      "source": [
        "# Group Equivariant Neural Networks\n",
        "\n",
        "---\n",
        "\n",
        "Notebook written by *Gabriele Cesa* (cesa.gabriele@gmail.com)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0LJwqB07397"
      },
      "source": [
        "# 3. Equivariant Networks\n",
        "\n",
        "We are finally ready to build our equivariant neural network.\n",
        "An equivariant neural network starts with a *lifting layer* to map an input image $x \\in X$ into a function $y \\in Y$ over the group $p4$.\n",
        "We can now alternate a sequence of non-linearities (e.g. ReLU) and *group-convolutions*, which map $Y$ to $Y$.\n",
        "\n",
        "Since we will apply this network to the task of image classification, in the last layer we apply a *pooling* operation as is normally done in a CNN; this time, however, we also pool over the $4$ rotational channels.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1wq7oC55nlr"
      },
      "source": [
        "### 3.1 Exercise. (5pt)\n",
        "\n",
        "Explain why we need to pool over the $4$ rotational channels.\n",
        "Why can't we keep the $4$ channels and use all of them as features of the final classifier?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7K5tTgn9iUc"
      },
      "source": [
        "#### 3.1 Insert Your Solution Here:\n",
        "\n",
        "> Because the label function of the image is invariant to the rotation of the image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZcmDFGU--j5"
      },
      "source": [
        "### 3.2 Implement A Deep Rotation Equivariant CNN (10 pt)\n",
        "\n",
        "Fianlly, you can combine the layers you have implemented earlier to build a rotation equivariant CNN.\n",
        "You model will take in input batches of $33 \\times 33$ images with a single input channel.\n",
        "\n",
        "The network performs a first *lifting layer* with $8$ output channels and is followed by $4$ *group convolution* with, respectively, $16$, $32$, $64$ and $128$ output channels.\n",
        "All convolutions have kernel size $3$, padding $1$ and stride $1$ and should use the bias.\n",
        "All convolutions are followed by `torch.nn.MaxPool3d` and `torch.nn.ReLU`.\n",
        "Note that we use `MaxPool3d` rather than `MaxPool2d` since our feature tensors have $5$ dimensions (there is an additional dimension of size $4$).\n",
        "In all pooling layers, we will use a kernel of size $(1, 3, 3)$, a stride of $(1, 2, 2)$ and a padding of $(0, 1, 1)$.\n",
        "This ensures pooling is done only on the spatial dimensions, while the rotational dimension is preserved.\n",
        "The last pooling layer, however, will also pool over the rotational dimension so it will use a kernel of size $(4, 3, 3)$, stride $(1, 1, 1)$ and padding $(0, 0, 0)$.\n",
        "\n",
        "Finally, the features extracted from the convolutional network are used in a linear layer to classify the input in $10$ classes.\n",
        "You don't need to apply a softmax layer on top.\n",
        "\n",
        "Follow the given template:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocEWdJ3s58dc"
      },
      "outputs": [],
      "source": [
        "class C4CNN(torch.nn.Module):\n",
        "  def __init__(self, n_classes=10):\n",
        "\n",
        "    super(C4CNN, self).__init__()\n",
        "\n",
        "    channels = [8, 16, 32, 64, 128]\n",
        "\n",
        "    ### BEGIN SOLUTION\n",
        "    layers = [\n",
        "            LiftingConv2d(in_channels = 1, out_channels = channels[0], kernel_size = 3, padding=1, bias=True),\n",
        "            torch.nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1)),\n",
        "            GroupConv2d(in_channels = channels[0], out_channels = channels[1], kernel_size = 3, padding=1, bias=True),\n",
        "            torch.nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1)),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            GroupConv2d(in_channels = channels[1], out_channels = channels[2], kernel_size = 3, padding=1, bias=True),\n",
        "            torch.nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1)),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            GroupConv2d(in_channels = channels[2], out_channels = channels[3], kernel_size = 3, padding=1, bias=True),\n",
        "            torch.nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1)),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            GroupConv2d(in_channels = channels[3], out_channels = channels[4], kernel_size = 3, padding=1, bias=True),\n",
        "            torch.nn.MaxPool3d(kernel_size=(4, 3, 3), stride=(1, 1, 1), padding=(0, 0, 0)),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            \n",
        "    ]\n",
        "    self.layers = torch.nn.Sequential(*layers)\n",
        "    self.head = torch.nn.Linear(channels[4], n_classes)\n",
        "    ### END SOLUTION\n",
        "\n",
        "  def forward(self, input: torch.Tensor):\n",
        "    \n",
        "    ### BEGIN SOLUTION\n",
        "    fts = self.layers(input)\n",
        "    fts = fts.reshape(input.shape[0], -1)\n",
        "    \n",
        "    return self.head(fts)\n",
        "    ### END SOLUTION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7CJu_wdDxmD"
      },
      "outputs": [],
      "source": [
        "# Let's try our model\n",
        "\n",
        "net = C4CNN()\n",
        "\n",
        "x = torch.randn(5, 1, 33, 33)\n",
        "\n",
        "y = net(x)\n",
        "\n",
        "assert y.shape == (5, 10)\n",
        "\n",
        "# Let's check if the model is invariant!\n",
        "\n",
        "gx = rotate(x, 1)\n",
        "\n",
        "gy = net(gx)\n",
        "\n",
        "assert torch.allclose(y, gy, atol=1e-5, rtol=1e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61UFHuGcFBJi"
      },
      "source": [
        "Let's try now to train out model.\n",
        "We will train the network on rotated MNIST.\n",
        "\n",
        "First of all, we need to download the dataset.\n",
        "\n",
        "Then, we will provide a dataloader for the dataset and a training script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMa9RaivEU8b",
        "outputId": "eb9686c4-e8a0-4607-dd9d-26ee68ad1756"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-08-09 22:36:39--  http://www.iro.umontreal.ca/~lisa/icml2007data/mnist_rotation_new.zip\n",
            "Resolving www.iro.umontreal.ca (www.iro.umontreal.ca)... 132.204.26.36\n",
            "Connecting to www.iro.umontreal.ca (www.iro.umontreal.ca)|132.204.26.36|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58424278 (56M) [application/zip]\n",
            "Saving to: ‘mnist_rotation_new.zip’\n",
            "\n",
            "mnist_rotation_new. 100%[===================>]  55.72M  14.5MB/s    in 4.7s    \n",
            "\n",
            "2021-08-09 22:36:44 (11.7 MB/s) - ‘mnist_rotation_new.zip’ saved [58424278/58424278]\n",
            "\n",
            "Archive:  mnist_rotation_new.zip\n",
            "  inflating: mnist_rotation_new/mnist_all_rotation_normalized_float_train_valid.amat  \n",
            "  inflating: mnist_rotation_new/mnist_all_rotation_normalized_float_test.amat  \n"
          ]
        }
      ],
      "source": [
        "# download the dataset\n",
        "!wget -nc http://www.iro.umontreal.ca/~lisa/icml2007data/mnist_rotation_new.zip\n",
        "# uncompress the zip file\n",
        "!unzip -n mnist_rotation_new.zip -d mnist_rotation_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82WKqC3jFWqJ"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms import ToTensor\n",
        "import tqdm\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "\n",
        "class MnistRotDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, mode, transform=None):\n",
        "        assert mode in ['train', 'test']\n",
        "            \n",
        "        if mode == \"train\":\n",
        "            file = \"mnist_rotation_new/mnist_all_rotation_normalized_float_train_valid.amat\"\n",
        "        else:\n",
        "            file = \"mnist_rotation_new/mnist_all_rotation_normalized_float_test.amat\"\n",
        "        \n",
        "        self.transform = transform\n",
        "\n",
        "        data = np.loadtxt(file, delimiter=' ')\n",
        "        \n",
        "        self.labels = data[:, -1].astype(np.int64)\n",
        "        self.num_samples = len(self.labels)    \n",
        "        self.images = data[:, :-1].reshape(-1, 28, 28).astype(np.float32)\n",
        "\n",
        "        # images in MNIST are only 28x28\n",
        "        # we pad them to have shape 33 x 33\n",
        "        self.images = np.pad(self.images, pad_width=((0,0), (2, 3), (2, 3)), mode='edge')\n",
        "\n",
        "        assert self.images.shape == (self.labels.shape[0], 33, 33)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.images[index], self.labels[index]\n",
        "        image = Image.fromarray(image)\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "train_set = MnistRotDataset('train', ToTensor())\n",
        "test_set = MnistRotDataset('test', ToTensor())\n",
        "\n",
        "def train_model(model: torch.nn.Module):\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(train_set, batch_size=64)\n",
        "  loss_function = torch.nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=5e-5, weight_decay=1e-5)\n",
        "\n",
        "  model.to(device)\n",
        "  model.train()\n",
        "\n",
        "  for epoch in tqdm.tqdm(range(30)):\n",
        "    \n",
        "    for i, (x, t) in enumerate(train_loader):\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        x = x.to(device)\n",
        "        t = t.to(device)\n",
        "\n",
        "        y = model(x)\n",
        "\n",
        "        loss = loss_function(y, t)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "    \n",
        "  return model\n",
        "\n",
        "\n",
        "def test_model(model: torch.nn.Module):\n",
        "  test_loader = torch.utils.data.DataLoader(test_set, batch_size=64)\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "      model.eval()\n",
        "      for i, (x, t) in tqdm.tqdm(enumerate(test_loader)):\n",
        "\n",
        "          x = x.to(device)\n",
        "          t = t.to(device)\n",
        "          \n",
        "          y = model(x)\n",
        "\n",
        "          _, prediction = torch.max(y.data, 1)\n",
        "          total += t.shape[0]\n",
        "          correct += (prediction == t).sum().item()\n",
        "  accuracy = correct/total*100.\n",
        "\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_O2KLRpNo2z"
      },
      "source": [
        "You can now trian and test your neural network.\n",
        "With the default parameters you should achieve an accuracy of roughly **93-94%**.\n",
        "Feel free to adapt the training procedure to improve the performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-Ib5ZW2I4V-",
        "outputId": "5e6d02b3-3160-4552-98a3-26333b856710"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [37:46<00:00, 75.54s/it]\n",
            "782it [02:20,  5.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 93.240\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model = C4CNN()\n",
        "\n",
        "model = train_model(model)\n",
        "\n",
        "acc = test_model(model)\n",
        "print(f'Test Accuracy: {acc :.3f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0uK2r0yR5fA"
      },
      "outputs": [],
      "source": [
        "# Let's check if the model is still invariant!\n",
        "\n",
        "x = torch.randn(5, 1, 33, 33)\n",
        "\n",
        "y = net(x)\n",
        "\n",
        "gx = rotate(x, 1)\n",
        "\n",
        "gy = net(gx)\n",
        "\n",
        "assert torch.allclose(y, gy, atol=1e-5, rtol=1e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qzEcXOcOLHL"
      },
      "source": [
        "### 3.3 Implement Equivariant CNN with Isotropic Convolution (5pt)\n",
        "\n",
        "For comparison, implement a similar network by using the `IsotropicConv2d` module you implement before.\n",
        "The model should have the same structure (kernel size, channels, padding, etc..) of the previous model.\n",
        "Except for the last one, in all convolutional layers you should increase by a factor of $4$ the number of output channels since the output of `IsotropicConv2d` is $4$ times smaller than the output of `GroupConv2d`, if the same value for `out_channels` is used.\n",
        "Note that in this model you will use `MaxPool2d` rather than `MaxPool3d`.\n",
        "However, in the last convolutional layer you can keep the same number of channels; we will not need to perform pooling here.\n",
        "\n",
        "Follow the given template:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BlXpItbNmNr"
      },
      "outputs": [],
      "source": [
        "class IsotropicCNN(torch.nn.Module):\n",
        "  def __init__(self, n_classes=10):\n",
        "\n",
        "    super(IsotropicCNN, self).__init__()\n",
        "\n",
        "    old_channels = [8, 16, 32, 64, 128]\n",
        "\n",
        "    channels = [4*c for c in old_channels[:-1]] + [old_channels[-1]]\n",
        "\n",
        "    ### BEGIN SOLUTION\n",
        "    layers = [\n",
        "            IsotropicConv2d(in_channels=1, out_channels=channels[0], bias=True),  \n",
        "            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "            IsotropicConv2d(in_channels = channels[0], out_channels = channels[1], bias=True),\n",
        "            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            IsotropicConv2d(in_channels = channels[1], out_channels = channels[2], bias=True),\n",
        "            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            IsotropicConv2d(in_channels = channels[2], out_channels = channels[3], bias=True),\n",
        "            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            IsotropicConv2d(in_channels = channels[3], out_channels = channels[4], bias=True),\n",
        "            torch.nn.MaxPool2d(kernel_size=3, stride=1, padding=0),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            \n",
        "    ]\n",
        "    self.layers = torch.nn.Sequential(*layers)\n",
        "    self.head = torch.nn.Linear(channels[4], n_classes)\n",
        "\n",
        "    ### END SOLUTION\n",
        "\n",
        "  def forward(self, input: torch.Tensor):\n",
        "    \n",
        "    ### BEGIN SOLUTION\n",
        "    fts = self.layers(input)\n",
        "    fts = fts.reshape(input.shape[0], -1)\n",
        "    \n",
        "    return self.head(fts)\n",
        "\n",
        "    ### END SOLUTION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATAo2a0GQeDT",
        "outputId": "c5008b24-44a0-4067-d720-a0e7e1d7f2ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        }
      ],
      "source": [
        "# Let's try our model\n",
        "\n",
        "net = IsotropicCNN()\n",
        "\n",
        "x = torch.randn(5, 1, 33, 33)\n",
        "\n",
        "y = net(x)\n",
        "\n",
        "assert y.shape == (5, 10)\n",
        "\n",
        "# Let's check if the model is invariant!\n",
        "\n",
        "gx = rotate(x, 1)\n",
        "\n",
        "gy = net(gx)\n",
        "\n",
        "assert torch.allclose(y, gy, atol=1e-5, rtol=1e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wh2l5tC-5JTb"
      },
      "source": [
        "You can now train and test your model.\n",
        "With the default parameters you should achieve an accuracy of roughly **45-50%**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDGfuzpKQpVc",
        "outputId": "5130cd17-a255-4465-9589-c36970faec2b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [38:31<00:00, 77.04s/it] \n",
            "782it [01:52,  6.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 52.976\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model = IsotropicCNN()\n",
        "\n",
        "model = train_model(model)\n",
        "\n",
        "acc = test_model(model)\n",
        "print(f'Test Accuracy: {acc :.3f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ov2K_hqsR_zR"
      },
      "outputs": [],
      "source": [
        "# Let's check if the model is still invariant!\n",
        "\n",
        "x = torch.randn(5, 1, 33, 33)\n",
        "\n",
        "y = net(x)\n",
        "\n",
        "gx = rotate(x, 1)\n",
        "\n",
        "gy = net(gx)\n",
        "\n",
        "assert torch.allclose(y, gy, atol=1e-5, rtol=1e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2x2CCRE1ULib"
      },
      "source": [
        "### 3.4 Exercise: Analyse the results (5pt)\n",
        "Do you note any difference between the performance of the `IsotropicCNN` and the `C4CNN`?\n",
        "What do you think causes this gap? Explain.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPU2_zs0Uesq"
      },
      "source": [
        "#### 3.4 Insert Your Solution Here:\n",
        "\n",
        "> YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmuhBQE3QyNZ"
      },
      "source": [
        "### 3.5 Batch Normalization (10 pt)\n",
        "\n",
        "Batch normalization is a common module in most deep neural networks.\n",
        "How can we define BatchNormalization to make it equivariant?\n",
        "\n",
        "Describe how an equivariant batch normalization can be constructed.\n",
        "Then, implement a batch normalization layer.\n",
        "Finally, build a new CNN model similar to `C4CNN` which uses your batchnormalization after each convolution.\n",
        "Train your model and test that it is still equivariant after training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39Fx_TMFhRuY"
      },
      "source": [
        "#### 3.5 Insert Your Solution Here:\n",
        "\n",
        "> YOUR ANSWER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aj1AYjDKhw4M"
      },
      "outputs": [],
      "source": [
        "class C4CNNWithBatchNorm(torch.nn.Module):\n",
        "  def __init__(self, n_classes=10):\n",
        "\n",
        "    super(C4CNNWithBatchNorm, self).__init__()\n",
        "\n",
        "    channels = [8, 16, 32, 64, 128]\n",
        "\n",
        "    ### BEGIN SOLUTION\n",
        "    layers = [\n",
        "            LiftingConv2d(in_channels = 1, out_channels = channels[0], kernel_size = 3, padding=1, bias=True),\n",
        "            torch.nn.InstanceNorm3d(num_features=channels[0]),\n",
        "            torch.nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1)),\n",
        "            GroupConv2d(in_channels = channels[0], out_channels = channels[1], kernel_size = 3, padding=1, bias=True),\n",
        "            torch.nn.InstanceNorm3d(num_features=channels[1]),\n",
        "            torch.nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1)),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            GroupConv2d(in_channels = channels[1], out_channels = channels[2], kernel_size = 3, padding=1, bias=True),\n",
        "            torch.nn.InstanceNorm3d(num_features=channels[2]),\n",
        "            torch.nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1)),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            GroupConv2d(in_channels = channels[2], out_channels = channels[3], kernel_size = 3, padding=1, bias=True),\n",
        "            torch.nn.InstanceNorm3d(num_features=channels[3]),\n",
        "            torch.nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1)),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            GroupConv2d(in_channels = channels[3], out_channels = channels[4], kernel_size = 3, padding=1, bias=True),\n",
        "            torch.nn.InstanceNorm3d(num_features=channels[4]),\n",
        "            torch.nn.MaxPool3d(kernel_size=(4, 3, 3), stride=(1, 1, 1), padding=(0, 0, 0)),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            \n",
        "    ]\n",
        "    self.layers = torch.nn.Sequential(*layers)\n",
        "    self.head = torch.nn.Linear(channels[4], n_classes)\n",
        "\n",
        "    ### END SOLUTION\n",
        "\n",
        "  def forward(self, input: torch.Tensor):\n",
        "    \n",
        "    ### BEGIN SOLUTION\n",
        "    fts = self.layers(input)\n",
        "    fts = fts.reshape(input.shape[0], -1)\n",
        "\n",
        "    return self.head(fts)\n",
        "\n",
        "    ### END SOLUTION\n",
        "\n",
        "\n",
        "# Let's try our model\n",
        "\n",
        "net = C4CNNWithBatchNorm()\n",
        "\n",
        "x = torch.randn(5, 1, 33, 33)\n",
        "\n",
        "y = net(x)\n",
        "\n",
        "assert y.shape == (5, 10)\n",
        "\n",
        "# Let's check if the model is invariant!\n",
        "\n",
        "gx = rotate(x, 1)\n",
        "\n",
        "gy = net(gx)\n",
        "\n",
        "assert torch.allclose(y, gy, atol=1e-5, rtol=1e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAdSgAb95QWU"
      },
      "source": [
        "You can now train and test your model.\n",
        "With the default parameters you should achieve an accuracy of roughly **95%**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EHe7DkRiI6V",
        "outputId": "a2a7bd6c-dabf-44aa-b3be-be99aa0762df"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 18/30 [29:22<19:20, 96.73s/it]"
          ]
        }
      ],
      "source": [
        "model = C4CNNWithBatchNorm()\n",
        "\n",
        "model = train_model(model)\n",
        "\n",
        "acc = test_model(model)\n",
        "print(f'Test Accuracy: {acc :.3f}')\n",
        "\n",
        "\n",
        "# Let's check if the model is still invariant!\n",
        "x = torch.randn(5, 1, 33, 33)\n",
        "y = net(x)\n",
        "gx = rotate(x, 1)\n",
        "gy = net(gx)\n",
        "assert torch.allclose(y, gy, atol=1e-5, rtol=1e-5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkWHybYLSvO1"
      },
      "source": [
        "# 4 Bonus Question (15 pt)\n",
        "\n",
        "This bonus question is not required to get 100% of the points.\n",
        "Solving this question, however, will give you a few additional points.\n",
        "We recommend solving this question only after you completed the rest of the notebook.\n",
        "\n",
        "So far, we have only considered rotation equivariance.\n",
        "At the beginning of the notebook, we defined the group $D_4$ of rotations and reflections.\n",
        "Together with translations, this forms the group $p4m$.\n",
        "\n",
        "In this exercise, you need to build a `D4CNN` model.\n",
        "This model is similar to `C4CNN` but the group convolutions will also include reflections.\n",
        "This means that, instead of $4$ rotational channels, the features will have $8$ channels (1 for each rotation and reflection).\n",
        "You should first implement the corresponding `D4LiftingConv2d` and `D4GroupConv2d` and then use them to build the `D4CNN`.\n",
        "\n",
        "Finally, test that the model is equivariant to both rotations and translations.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Benjamin_BENTEKE_Tutorial_on_Group_Convolutional_Networks_AMMI_Geometric_Deep_Learning_Course.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
